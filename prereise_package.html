
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>PreREISE &#8212; documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="shortcut icon" href="_static/favicon.svg"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="PostREISE" href="postreise/index.html" />
    <link rel="prev" title="PowerSimData" href="powersimdata/index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p><a class="reference external" href="https://github.com/psf/black"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg" /></a>
<img alt="Tests" src="https://github.com/Breakthrough-Energy/PreREISE/workflows/Pytest/badge.svg" /></p>
<section id="prereise">
<h1>PreREISE<a class="headerlink" href="#prereise" title="Permalink to this headline">¶</a></h1>
<p>This package gathers and builds demand, hydro, solar, and wind profiles. The profiles
are needed to run scenarios on the U.S. electrical grid. PreREISE is part of a set of
packages representing Breakthrough Energy’s power system model.</p>
<p>More information regarding the installation of the model as well as the contribution
guide can be found <a class="reference external" href="https://breakthrough-energy.github.io/docs/">here</a>.</p>
<section id="setup-install">
<h2>1. Setup/Install<a class="headerlink" href="#setup-install" title="Permalink to this headline">¶</a></h2>
<p>Here are the instructions to install the <strong>PreREISE</strong> package. We strongly recommend
that you pick one of the following options.</p>
<section id="a-using-pipenv">
<h3>A. Using pipenv<a class="headerlink" href="#a-using-pipenv" title="Permalink to this headline">¶</a></h3>
<p>If not already done, install <code class="docutils literal notranslate"><span class="pre">pipenv</span></code> by following the instructions on their
<a class="reference external" href="https://pipenv.pypa.io/en/latest/">webpage</a>. Then run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pipenv sync
pipenv shell
</pre></div>
</div>
<p>in the root folder of the package. The first command will create a virtual environment
and install the dependencies. The second command will activate the environment.</p>
</section>
<section id="b-using-the-requirements-txt-file">
<h3>B. Using the <em><strong>requirements.txt</strong></em> file<a class="headerlink" href="#b-using-the-requirements-txt-file" title="Permalink to this headline">¶</a></h3>
<p>First create an environment using <code class="docutils literal notranslate"><span class="pre">venv</span></code> (more details
<a class="reference external" href="https://docs.python.org/3/library/venv.html">here</a>). Note that <code class="docutils literal notranslate"><span class="pre">venv</span></code> is included in
the Python standard library and requires no additional installation. Then, activate your
environment and run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install -r requirements.txt
</pre></div>
</div>
<p>in the root folder of the package.</p>
</section>
<section id="c-path">
<h3>C. Path<a class="headerlink" href="#c-path" title="Permalink to this headline">¶</a></h3>
<p>Whatever method you choose, if you wish to access the modules located in <strong>PreREISE</strong>
from anywhere on your machine, do:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install .
</pre></div>
</div>
<p>in the root folder of your package or alternatively, setup the <code class="docutils literal notranslate"><span class="pre">PYTHONPATH</span></code> global
variable.</p>
</section>
</section>
<section id="gather-data-for-simulation">
<h2>2. Gather Data for Simulation<a class="headerlink" href="#gather-data-for-simulation" title="Permalink to this headline">¶</a></h2>
<p>This module aims at gathering the required data for building the profiles</p>
<section id="profile-naming-convention">
<h3>Profile Naming Convention<a class="headerlink" href="#profile-naming-convention" title="Permalink to this headline">¶</a></h3>
<p>We call the time series profiles directly generated from mathematical/heuristic models
without any scaling (as we do in different scenarios) as ‘raw’ profiles.</p>
<p>The name of a raw profile in the simulation framework must be of the form:</p>
<p>[<strong>type</strong>]_v[<strong>D</strong>],</p>
<p>where <strong>type</strong> specifies the profile type  (’<em>demand</em>’, ‘<em>hydro</em>’, ‘<em>solar</em>’, ‘<em>wind</em>’)
and <strong>D</strong> refers to the date the file has been created. Month (3 letters, e.g., Jan) and
year (4 digits, e.g., 2021) are used for the date. If two or more profiles of the same
<strong>type</strong> are created the same month of the same year, the different versions will be
differentiated using a lowercase letter added right after the year, e.g,
<em><strong>demand_vJan2021.csv</strong></em> (first), <em><strong>demand_vJan2021b.csv</strong></em> (second),
<em><strong>demand_vJan2021c.csv</strong></em> (third) and so forth.</p>
</section>
<section id="a-wind-data">
<h3>A. Wind data<a class="headerlink" href="#a-wind-data" title="Permalink to this headline">¶</a></h3>
<section id="i-rapid-refresh">
<h4>i. Rapid Refresh<a class="headerlink" href="#i-rapid-refresh" title="Permalink to this headline">¶</a></h4>
<p><a class="reference external" href="https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/rapid-refresh-rap">RAP</a> (Rapid Refresh) is the continental-scale NOAA hourly-updated
assimilation/modeling system operational at the National Centers for Environmental
Prediction (NCEP). RAP covers North America and is comprised primarily of a numerical
weather model and an analysis system to initialize that model. RAP provides, every hour
ranging from May 2012 to date, the U and V components of the wind speed at 80 meter
above ground on a 13x13 square kilometer resolution grid every hour. Data can be
retrieved using the NetCDF Subset Service. Information on this interface is described
<a class="reference external" href="https://www.unidata.ucar.edu/software/thredds/current/tds/reference/NetcdfSubsetServiceReference.html">here</a>. Note that the dataset is incomplete and, consequently, missing entries
need to be imputed.</p>
<p>Once the U and V components of the wind are converted to a non-directional wind speed
magnitude, this speed is converted to power using wind turbine power curves. Since real
wind farms are not currently mapped to TAMU network farms, a capacity-weighted average
wind turbine power curve is created for each state based on the turbine types reported
in <a class="reference external" href="https://www.eia.gov/electricity/data/eia860/">EIA Form 860</a>. The wind turbine curve for each real wind farm is looked up
from a database of curves (or the <em>IEC class 2</em> power curve provided by NREL in the
<a class="reference external" href="https://www.nrel.gov/docs/fy14osti/61714.pdf">WIND Toolkit documentation</a>) is used for turbines without curves in the
database), and scaled from the real hub heights to 80m hub heights using an alpha of
0.15. These height-scaled, turbine-specific curves are averaged to obtain a state curve
translating wind speed to normalized power. States without wind farms in
<a class="reference external" href="https://www.eia.gov/electricity/data/eia860/">EIA Form 860</a> are represented by the <em>IEC class 2</em> power curve.</p>
<p>Each turbine curve represents the instantaneous power from a single turbine for a given
wind speed. To account for spatio-temporal variations in wind speed (i.e. an hourly
average wind speed that varies through the hour, and a point-specific wind speed that
varies throughout the wind farm), a distribution is used: a normal distribution with
standard deviation of 40% of the average wind speed. This distribution tends to boost
the power produced at lower wind speeds (since the power curve in this region is convex)
and lower the power produced at higher wind speeds (since the power curve in this region
is concave as the turbine tops out, and shuts down at higher wind speeds). This tracks
with the wind-farm level data shown in NREL’s validation report.</p>
<p>Check out the <strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/winddata/rap/demo/rap_demo.ipynb">rap_demo.ipynb</a></strong> notebook for demo.</p>
</section>
</section>
<section id="b-solar-data">
<h3>B. Solar data<a class="headerlink" href="#b-solar-data" title="Permalink to this headline">¶</a></h3>
<section id="i-the-gridded-atmospheric-wind-integration-national-dataset-toolkit">
<h4>i. The Gridded Atmospheric Wind Integration National Dataset Toolkit<a class="headerlink" href="#i-the-gridded-atmospheric-wind-integration-national-dataset-toolkit" title="Permalink to this headline">¶</a></h4>
<p>The <a class="reference external" href="https://www.nrel.gov/grid/wind-toolkit.html">Gridded Atmospheric WIND (Wind Integration National Dataset) Toolkit</a>
provides 1-hour resolution irradiance data for 7 years, ranging from 2007 to 2013, on a
uniform 2x2 square kilometer grid that covers the continental U.S., the Baja Peninsula,
and parts of the Pacific and Atlantic oceans. Data can be accessed using the Highly
Scalable Data Service. NREL wrote <a class="reference external" href="https://github.com/NREL/hsds-examples">example notebooks</a> that demonstrate
how to access the data.</p>
<p>Power output is estimated using a simple normalization procedure. For each solar plant
location the hourly Global Horizontal Irradiance (GHI) is divided by the maximum GHI
over the period considered and multiplied by the capacity of the plant. This procedure
is referred to as naive since it only accounts for the plant capacity. Note that other
factors can possibly affect the conversion from solar radiation at ground to power such
as the temperature at the site as well as many system configuration including tracking
technology.</p>
<p>Check out the <strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/solardata/ga_wind/demo/ga_wind_demo.ipynb">ga_wind_demo.ipynb</a></strong> notebook for demo.</p>
</section>
<section id="ii-the-national-solar-radiation-database">
<h4>ii. The National Solar Radiation Database<a class="headerlink" href="#ii-the-national-solar-radiation-database" title="Permalink to this headline">¶</a></h4>
<p><a class="reference external" href="https://nsrdb.nrel.gov/">NSRDB (National Solar Radiation Database)</a> provides 1-hour resolution solar
radiation data, ranging from 1998 to 2016, for the entire U.S. and a growing list of
international locations on a 4x4 square kilometer grid. Data can be accessed via an
<a class="reference external" href="https://developer.nrel.gov/docs/solar/nsrdb/">API</a>. Note that the Physical Solar Model v3 is used.</p>
<p>An API key is required to access and use the above databases. Get your own API key
<a class="reference external" href="https://developer.nrel.gov/signup/">here</a>.</p>
<p>Here, the power output can be estimated using the previously presented naive method or a
more sophisticated one. The latter uses the System Adviser Model (<a class="reference external" href="https://sam.nrel.gov/">SAM</a>)
developed by NREL. The developer tools for creating renewable energy system models can
be downloaded <a class="reference external" href="https://sam.nrel.gov/sdk">here</a>. Irradiance data along with other meteorological
parameters must first be retrieved from NSRDB for each site. This information are then
fed to the SAM Simulation Core (SCC) and the power output is retrieved. The SSC reflect
the technology used: photovoltaic (PV), solar water heating and concentrating solar
power (CSP). The <a class="reference external" href="https://nrel-pysam.readthedocs.io/en/master/modules/Pvwattsv7.html"><em>PVWatts v7</em></a> model is used for all the solar plants in
the grid. The system size (in DC units) and the array type (fixed open rack,
backtracked, 1-axis and 2-axis) is set for each solar plant whereas a unique value of
1.25 is used for the DC to AC ratio (see article from EIA on inverter loading ratios
<a class="reference external" href="https://www.eia.gov/todayinenergy/detail.php?id=35372">here</a>). Otherwise, all other
input parameters of the <em>PVWatts</em> model are set to their default values. EIA reports in
<a class="reference external" href="https://www.eia.gov/electricity/data/eia860/">form 860</a> the array type used by each solar PV plant. For each plant in our
network, the array type is a combination of the three technology that is calculated
using the capacity weighted average of the array type of all the plants in
<a class="reference external" href="https://www.eia.gov/electricity/data/eia860/">EIA Form 860</a> that are located in the same state. If no plants are reported
in <a class="reference external" href="https://www.eia.gov/electricity/data/eia860/">EIA Form 860</a> for a particular state we then use the information of all
the plants belonging to the same interconnect.</p>
<p>The naive and the SAM methods are used in the
<strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/solardata/nsrdb/demo/nsrdb_naive_demo.ipynb">nsrdb_naive_demo.ipynb</a></strong> and
<strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/solardata/nsrdb/demo/nsrdb_sam_demo.ipynb">nsrdb_sam_demo.ipynb</a></strong> demo notebooks, respectively.</p>
</section>
</section>
<section id="c-hydro-data">
<h3>C. Hydro Data<a class="headerlink" href="#c-hydro-data" title="Permalink to this headline">¶</a></h3>
<section id="i-hydro-v1">
<h4>i. Hydro v1<a class="headerlink" href="#i-hydro-v1" title="Permalink to this headline">¶</a></h4>
<p>EIA (Energy Information Administration) published monthly capacity factors for hydro
plants across the country. This dataset (available <a class="reference external" href="https://www.eia.gov/electricity/annual/html/epa_04_08_b.html">here</a>) is used to produce
a profile for each hydro plant in the grid. Note that we are using the same set of
capacity factor independently of the geographical location of the plant. As a result,
the profile of all the hydro plants in the grid will have the same shape. Only the power
output will differ (the scale of the profile).</p>
<p>Check out the <strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/hydrodata/eia/demo/hydro_v1_demo.ipynb">hydro_v1_demo.ipynb</a></strong> notebook for demo.</p>
</section>
<section id="ii-hydro-v2">
<h4>ii. Hydro v2<a class="headerlink" href="#ii-hydro-v2" title="Permalink to this headline">¶</a></h4>
<section id="a-western">
<h5>a. Western<a class="headerlink" href="#a-western" title="Permalink to this headline">¶</a></h5>
<p>Hydro hourly profile v2 for Western consists of two components: profile shape to capture
the hourly variance and monthly total generation to capture the historical summation.
EIA published monthly total generation for each hydro plant by state in form EIA 923
(available <a class="reference external" href="https://www.eia.gov/electricity/data/eia923/">here</a>).</p>
<p>Given that Washington state has the most hydro generation in the Western
Interconnection, we use the aggregated generation of the top 20 US Army Corps managed
hydro dams in Northwestern US (primarily in WA) as the shape of this hydro profile v2
for all the states in Western except for California and Wyoming. The data is obtained
via <a class="reference external" href="http://www.nwd-wc.usace.army.mil/dd/common/dataquery/www/">US Army Corps of Engineers Northwestern Division DataQuery Tool
2.0</a>.</p>
<p>Observed from system daily outlook of California ISO (available <a class="reference external" href="http://www.caiso.com/TodaysOutlook/Pages/default.aspx">here</a>),
the hydro generation profile follows closely to the net demand profile. Thus, we
construct the shape curve of hydro profile v2 in CA using the net demand profile of CA
in the base case scenario (Scenario 87). As for Wyoming, due to the small name plate
capacities of the hydro generators, we simply apply a constant shape curve to avoid
peak-hour violation of maximum capacity.</p>
<p>The final hydro profile v2 is built by scaling the corresponding shape curves based on
the monthly total generation record in each state, then decomposing into plant-level
profiles proportional to the generator capacities. Check out the
<strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/hydrodata/eia/demo/western_hydro_v2_demo.ipynb">western_hydro_v2_demo.ipynb</a></strong> notebook for demo.</p>
</section>
<section id="b-texas">
<h5>b.Texas<a class="headerlink" href="#b-texas" title="Permalink to this headline">¶</a></h5>
<p>The Electric Reliability Council of Texas (ERCOT) published actual generation by fuel
type for each 15 minute settlement interval. For details, see the fuel mix report
available <a class="reference external" href="http://www.ercot.com/gridinfo/generation/">here</a>. Given this time-series historical data, similarly
with the western case, the final hydro profile v2 for Texas is constructed by
decomposing the total hydro generation profile proportional to the generator capacities.
Check out the <strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/hydrodata/eia/demo/texas_hydro_v2_demo.ipynb">texas_hydro_v2_demo.ipynb</a></strong> notebook for
demo.</p>
</section>
</section>
<section id="iii-hydro-v3">
<h4>iii. Hydro v3<a class="headerlink" href="#iii-hydro-v3" title="Permalink to this headline">¶</a></h4>
<p>This methodology is designed to generate hourly plant level hydro profile for Eastern,
i.e. eastern hydro v3, which has following features:</p>
<ul class="simple">
<li><p>Pumped storage hydro (HPS) and conventional hydro (HYC) are handled separately.</p></li>
<li><p>Historical hourly hydro profiles of four ISOs (ISONE, NYISO, PJM and SPP), are used
directly as regional total hydro profiles to start with.</p></li>
<li><p>For the rest of areas in Eastern Interconnect, which are not covered by the four
ISOs, the hydro profile is generated in the same way as western hydro profile v2.</p></li>
</ul>
<p>Note that usa hydro v3 is the concatenation of eastern hydro v3, western hydro v2 and
texas hydro v2</p>
<section id="a-pumped-storage-hydro">
<h5>a. Pumped Storage Hydro<a class="headerlink" href="#a-pumped-storage-hydro" title="Permalink to this headline">¶</a></h5>
<p>HPS profile for each plant in <a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/hydrodata/eia/demo/eastern_hydro_v3_demo/hps_plants_eastern.xlsx">hps_plants_eastern.xlsx</a>,
<strong>‘all_plantIDs’</strong> sheet, is generated based on the deterministic model presented in
<strong>‘profile’</strong> sheet. The HPS profile model is designed based on local time. The plant
level HPS profiles are generated considering the local time and daylight-saving schedule
of the locations of the corresponding buses. However, during the sanity check
afterwards, it turns out that this model overestimates the HPS output, the final profile
is further scaled by 0.65 to be in agreement with values reported in <a class="reference external" href="https://www.eia.gov/electricity/data/eia923/">EIA 923</a>.</p>
</section>
<section id="b-conventional-hydro">
<h5>b. Conventional Hydro<a class="headerlink" href="#b-conventional-hydro" title="Permalink to this headline">¶</a></h5>
<p>The buses of the HYC plants were associated to five regions (ISONE, NYISO, PJM, SPP and
the area uncovered by the aforementioned regions) using the same methodology employed
for eastern demand v5. Check Demand Data section below for details. For HYC plants
locating inside the territories of the four ISOs, we decompose the total historical
profile of each ISO into plant -level profiles proportional to the generator capacities.
The time series profile data of each ISO is obtained via their official websites:
<a class="reference external" href="https://www.iso-ne.com/isoexpress/">ISONE</a>, <a class="reference external" href="http://mis.nyiso.com/public/P-63list.htm">NYISO</a>, <a class="reference external" href="http://dataminer2.pjm.com/feed/gen_by_fuel">PJM</a>, <a class="reference external" href="https://marketplace.spp.org/pages/generation-mix-historical">SPP</a>.</p>
<p>For the rest of HYC plants lying outside the four ISO regions, we apply the same
methodology that is used to generate hydro profile of California in Western hydro v2
(see details in the above subsection). The net demand profile is obtained from Eastern
base case scenario (Scenario 397). The monthly net generations for a state is split
proportional to the total capacities of the generators if the corresponding state is
covered partially by the four ISOs mentioned above.</p>
<p>The final Eastern hydro profile v3 is built by stitching the three parts together:
pumped storage hydro profiles, conventional hydro profiles within the four ISO regions
and conventional hydro profiles in the rest areas . Check out
<strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/hydrodata/eia/demo/eastern_hydro_v3_demo/eastern_hydro_v3_demo.ipynb">eastern_hydro_v3_demo.ipynb</a></strong> notebook for demo.</p>
</section>
</section>
</section>
<section id="d-demand-data">
<h3>D. Demand Data<a class="headerlink" href="#d-demand-data" title="Permalink to this headline">¶</a></h3>
<p><em>Eastern V6</em></p>
<p>The two BAs, SPP and MISO, consist of big areas from north to south. It is unlikely that
the whole area covered by these big BAs have the same hourly profile shape. Eastern
demand v6 addresses the issue by further splitting these two BAs into subareas. We
replace overall MISO and SPP demand with subarea demand obtained directly from contact
at the BAs. We use overall numbers from EIA and use the fractional subarea demand as the
basis to split the MISO and SPP demand.</p>
<p>The hourly subarea demand profiles for SPP and MISO is reported on their official
websites respectively (check <a class="reference external" href="https://marketplace.spp.org/pages/hourly-load">SPP hourly
load</a>, <a class="reference external" href="https://www.misoenergy.org/markets-and-operations/real-time--market-data/market-reports/#nt=%2FMarketReportType%3ADay-Ahead&amp;t=10&amp;p=0&amp;s=MarketReportPublished&amp;sd=desc">MISO hourly
load</a>).
The geographical definitions of these subareas are obtained directly from contact at the
BAs via either customer service or internal request management system (check
<a class="reference external" href="https://spprms.issuetrak.com/Login.asp">RMS</a>). Given the geographical definitions, i.e.
list of counties for each subarea, each bus is mapped to the subarea it belongs to.</p>
<p>The overall procedure is similar to v5 except we generate subarea mapping as well as prepare subarea demand from files.</p>
<p><em>Eastern V5</em></p>
<p>Demand data are obtained from EIA, to whom Balancing Authorities have submitted their
data. The data can be obtained using an API as demonstrated in
<strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/demanddata/eia/demo/demo_Eastern_v5/eastern_demand_v5_demo.ipynb">eastern_demand_v5_demo.ipynb</a></strong> notebook.</p>
<p>Module <code class="docutils literal notranslate"><span class="pre">get_eia_data</span></code> contains functions that converts the data into data frames for
further processing, as performed in
<strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/demanddata/eia/demo/demo_Eastern_v5/eastern_demand_v5_demo.ipynb">eastern_demand_v5_demo.ipynb</a></strong>.</p>
<p>To output the demand profile, cleaning steps were applied to the EIA data for Eastern
V5. We used adjacent demand data to fill missing values using a series of rules:</p>
<ol class="simple">
<li><p>Monday: look forward one day</p></li>
<li><p>Tuesday - Thursday: average of look forward one day and look back one day</p></li>
<li><p>Friday: look back one day</p></li>
<li><p>Saturday: look forward one day</p></li>
<li><p>Sunday: look back one day</p></li>
</ol>
<p>If data is still missing after applying the above rules, week ahead and week behind data
is used:</p>
<ol class="simple">
<li><p>Monday: look forward two days</p></li>
<li><p>Tuesday: look forward two days</p></li>
<li><p>Wednesday: average of look forward two days and look back two days</p></li>
<li><p>Thursday: look back two days</p></li>
<li><p>Friday: look back two days</p></li>
<li><p>Saturday - Sun: average of look back one week and look forward one week</p></li>
</ol>
<p>If data is still missing after applying the above rules, week ahead and week behind data
is used:</p>
<ol class="simple">
<li><p>Monday - Sunday: average of look back one week and look forward one week</p></li>
</ol>
<p>The next step was outlier detection. The underlying physical rationale is that demand
changes are mostly driven by weather temperature changes (first or higher order), and
thermal mass limits the rate at which demand values can change. Outliers were detected
using a z-score threshold value of 3. These outliers are then replaced by linear
interpolation.</p>
<p>The BA counts were then distributed across each region where the BA operates, using the
region populations as weights. For example, if a BA operates in both WA and OR, the
counts for WA are weighted by the fraction of the total counts in WA relative to the
total population of WA and OR.</p>
<p>Lastly, buses were mapped to counties. This step requires an input data file that stores
the list of counties in each BA area territory. Some data cleaning was necessary to deal
with inconsistent county names. We also implemented a check if there are buses where BA
is empty/not found, which is due to bus being outside of United States. These were fixed
manually by assigning the bus to the nearest county.</p>
<p><em>Legacy Description</em></p>
<p>Demand data are obtained from EIA, to whom Balancing Authorities have submitted their
data. The data can be obtained either by direct download from their database using an
API or by download of Excel spreadsheets. An API key is required for the API download
and this key can be obtained by a user by registering at
<a class="reference external" href="https://www.eia.gov/opendata/">https://www.eia.gov/opendata/</a>.</p>
<p>The direct download currently contains only published demand data. The Excel
spreadsheets include original and imputed demand data, as well as results of various
data quality checks done by EIA. Documentation about the dataset can be found
<a class="reference external" href="https://www.eia.gov/realtime_grid/docs/userguide-knownissues.pdf">here</a>. Excel spreadsheets can be downloaded by clicking on the links in
page 9 (Table of all US and foreign connected balancing authorities).</p>
<p>Module <code class="docutils literal notranslate"><span class="pre">get_eia_data</span></code> contains functions that converts the data into data frames for
further processing.</p>
<p>To test EIA download (This requires an EIA API key):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.eia.tests</span> <span class="kn">import</span> <span class="n">test_get_eia_data</span>

<span class="n">test_get_eia_data</span><span class="o">.</span><span class="n">test_eia_download</span><span class="p">()</span>
</pre></div>
</div>
<p>To test EIA download from Excel:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.eia.tests</span> <span class="kn">import</span> <span class="n">test_get_eia_data</span>

<span class="n">test_get_eia_data</span><span class="o">.</span><span class="n">test_from_excel</span><span class="p">()</span>
</pre></div>
</div>
<p>The <strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/demanddata/eia/demo/assemble_ba_from_excel_demo.ipynb">assemble_ba_from_excel_demo.ipynb</a></strong> notebook illustrates usage.</p>
<p>To output the demand profile, cleaning steps were applied to the EIA data:   1) missing
data imputation - the EIA method was used, i.e., EIA published data was used; beyond
this, NA’s were converted to float zeros;   2) missing hours were added.</p>
<p>The BA counts were then distributed across each region where the BA operates, using the
region populations as weights. For example, if a BA operates in both WA and OR, the
counts for WA are weighted by the fraction of the total counts in WA relative to the
total population of WA and OR.</p>
<p>The next step consist in detecting outliers by looking for large changes in the slope of
the demand data. The underlying physical rationale is that demand changes are mostly
driven by weather temperature changes (first or higher order), and thermal mass limits
the rate at which demand values can change. By looking at the slope of demand data, it
is seen that the slope distribution is normally distributed, and outliers can be easily
found by imposing a z-score threshold value of 3. These outliers are then replaced by
linear interpolation.</p>
<p>To test outlier detection, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.eia.tests</span> <span class="kn">import</span> <span class="n">test_clean_data</span>

<span class="n">test_clean_data</span><span class="o">.</span><span class="n">test_slope_interpolate</span><span class="p">()</span>
</pre></div>
</div>
<p>The <strong><a class="reference external" href="https://github.com/Breakthrough-Energy/PreREISE/blob/develop/prereise/gather/demanddata/eia/demo/ba_anomaly_detection_demo.ipynb">ba_anomaly_detection_demo.ipynb</a></strong> notebook illustrates usage.</p>
</section>
<section id="e-nrel-electrification-futures-study-demand-and-flexibility-data">
<h3>E. NREL Electrification Futures Study Demand and Flexibility Data<a class="headerlink" href="#e-nrel-electrification-futures-study-demand-and-flexibility-data" title="Permalink to this headline">¶</a></h3>
<p>The National Renewable Energy Laboratory (NREL) has developed the Electrification
Futures Study (EFS) to project and study future sectoral demand changes as a result of
impending widespread electrification. As a part of the EFS, NREL has published multiple
reports (dating back to 2017) that describe their process for projecting demand-side
growth and provide analysis of their preliminary results; all of NREL’s published EFS
reports can be found <a class="reference external" href="https://www.nrel.gov/analysis/electrification-futures.html">here</a>. Accompanying their reports, NREL has published
data sets that include hourly load profiles that were developed using processes
described in the EFS reports. These hourly load profiles represent state-by-state
end-use electricity demand across four sectors (Transportation, Residential Buildings,
Commercial Buildings, and Industry) for three electrification scenarios (Reference,
Medium, and High) and three levels of technology advancements (Slow, Moderate, and
Rapid). Load profiles are provided for six separate years: 2018, 2020, 2024, 2030, 2040,
and 2050. The base demand data sets and further accompanying information can be found
<a class="reference external" href="https://data.nrel.gov/submissions/126">here</a>. In addition to demand growth projections, NREL has also published
data sets that include hourly profiles for flexible load. These data sets indicate the
amount of demand that is considered to be flexible, as determined through the EFS. The
flexibility demand profiles consider two scenarios of flexibility (Base and Enhanced),
in addition to the classifications for each sector, electrification scenario, technology
advancement, and year. The flexible demand data sets and further accompanying
information can be found <a class="reference external" href="https://data.nrel.gov/submissions/127">here</a>.</p>
<p>Widespread electrification can have a large impact on future power system planning
decisions and operation. While increased electricity demand can have obvious
implications for generation and transmission capacity planning, new electrified demand
(e.g., electric vehicles, air source heat pumps, and heat pump water heaters) offers
large amounts of potential operational flexibility to grid operators. This flexibility
by demand-side resources can result in demand shifting from times of peak demand to
times of peak renewable generation, presenting the opportunity to defer generation and
transmission capacity upgrades. To help electrification impacts be considered properly,
this package has the ability to access NREL’s EFS demand data sets. Currently, users can
access the base demand profiles, allowing the impacts of demand growth due to vast
electrification to be explored. Users can also access the EFS flexible demand profiles,
though integration of demand-side flexibility modeling to the rest of Breakthrough
Energy Sciences’ production cost model will be included in a future release.</p>
<section id="i-downloading-and-extracting-efs-demand-and-flexibility-data">
<h4>I. Downloading and Extracting EFS Demand and Flexibility Data<a class="headerlink" href="#i-downloading-and-extracting-efs-demand-and-flexibility-data" title="Permalink to this headline">¶</a></h4>
<p>The EFS demand data sets are stored on the ‘NREL Data Catalog’ in .zip files. The ‘NREL
Data Catalog’ contains nine .zip files, one for each combination of electrification
scenario and technology advancement. The <em><strong>.csv</strong></em> file compressed within the .zip file
contains the sectoral demand for each state and year. This data can be downloaded and
extracted using the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.get_efs_data</span> <span class="kn">import</span> <span class="n">download_demand_data</span>

<span class="n">download_demand_data</span><span class="p">(</span><span class="n">es</span><span class="p">,</span> <span class="n">ta</span><span class="p">,</span> <span class="n">fpath</span><span class="p">,</span> <span class="n">sz_path</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">es</span></code> is the set of electrification scenarios to be downloaded, <code class="docutils literal notranslate"><span class="pre">ta</span></code> is the set of
technology advancements to be downloaded, <code class="docutils literal notranslate"><span class="pre">fpath</span></code> is the file path to which the NREL EFS
data will be downloaded, and <code class="docutils literal notranslate"><span class="pre">sz_path</span></code> is the file path to which <a class="reference external" href="https://www.7-zip.org/">7-Zip</a> is
located for Windows users. <code class="docutils literal notranslate"><span class="pre">es</span></code> and <code class="docutils literal notranslate"><span class="pre">ta</span></code> default to downloading each of the
electrification scenarios and technology advancements, respectively. <code class="docutils literal notranslate"><span class="pre">fpath</span></code> defaults to
downloading the EFS data to the current directory. <code class="docutils literal notranslate"><span class="pre">sz_path</span></code> defaults to the default
installation location for 7-Zip.</p>
<p>The EFS flexibility data sets are also stored on the ‘NREL Data Catalog’ in .zip files.
The flexibility data is stored differently from the base demand data, with flexibility
data stored in three separate .zip files, one for each electrification scenario. The
<em><strong>.csv</strong></em> file compressed within the .zip file contains the sectoral flexibility for
each state, year, technology advancement, and flexibility scenario. This data can be
downloaded and extracted using the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.get_efs_data</span> <span class="kn">import</span> <span class="n">download_flexibility_data</span>

<span class="n">download_flexibility_data</span><span class="p">(</span><span class="n">es</span><span class="p">,</span> <span class="n">fpath</span><span class="p">,</span> <span class="n">sz_path</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">es</span></code> is the set of electrification scenarios to be downloaded, <code class="docutils literal notranslate"><span class="pre">fpath</span></code> is the file
path to which the NREL EFS data will be downloaded, and <code class="docutils literal notranslate"><span class="pre">sz_path</span></code> is the file path to
which 7-Zip is located for Windows users. <code class="docutils literal notranslate"><span class="pre">es</span></code> defaults to downloading each of the
electrification scenarios. <code class="docutils literal notranslate"><span class="pre">fpath</span></code> defaults to downloading the EFS data to the current
directory. <code class="docutils literal notranslate"><span class="pre">sz_path</span></code> defaults to the default installation location for 7-Zip.</p>
<p>Although downloading the .zip files is a simple task, extracting the <em><strong>.csv</strong></em> files
using Python is more challenging. The .zip files stored on the ‘NREL Data Catalog’ are
compressed using a compression method (Deflate64, or compression type 9) that is not
currently supported by <code class="docutils literal notranslate"><span class="pre">zipfile</span></code>, a popular Python package for working with .zip files.
To extract the <em><strong>.csv</strong></em> files in an automated fashion, it is necessary to use either
the Command Prompt or the Terminal, depending on the user’s operating system. For
machines running macOS or Linux, the Terminal’s extraction tools are capable of
accessing the <em><strong>.csv</strong></em> file. However, Windows machines are unable to extract the
<em><strong>.csv</strong></em> files using the Command Prompt’s extraction tools due to the compression
method. For Windows users with 7-Zip, the <em><strong>.csv</strong></em> file can be extracted, so long as
7-Zip is installed in the default location. If none of these methods succeed in
extracting the <em><strong>.csv</strong></em> file, then users can extract the file manually by going to the
.zip file’s location and using their extraction tool of choice. For instance, even
though Windows’ Command Prompt extraction tools do not work, the native extraction tool
built into Windows’ File Explorer does work.</p>
</section>
<section id="ii-splitting-the-efs-demand-and-flexibility-data-by-sector-and-year">
<h4>II. Splitting the EFS Demand and Flexibility Data by Sector and Year<a class="headerlink" href="#ii-splitting-the-efs-demand-and-flexibility-data-by-sector-and-year" title="Permalink to this headline">¶</a></h4>
<p>The EFS demand data for a given electrification scenario and technology advancement is
provided for each sector and each year. Although the sectoral demand is eventually
aggregated for a given year (see next subsection), splitting the demand by sector can be
useful, especially for users that may only want to use a subset of the EFS sectoral
demand (perhaps to pair with their own sectoral demand data). EFS demand data for a
single electrification scenario and technology advancement pair can be split by sector
as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.get_efs_data</span> <span class="kn">import</span> <span class="n">partition_demand_by_sector</span>

<span class="n">sect_dem</span> <span class="o">=</span> <span class="n">partition_demand_by_sector</span><span class="p">(</span><span class="n">es</span><span class="p">,</span> <span class="n">ta</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">sect</span><span class="p">,</span> <span class="n">fpath</span><span class="p">,</span> <span class="n">save</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">es</span></code> is a string describing a single electrification scenario, <code class="docutils literal notranslate"><span class="pre">ta</span></code> is a string
describing a single technology advancement, <code class="docutils literal notranslate"><span class="pre">year</span></code> is an integer describing the included
year, <code class="docutils literal notranslate"><span class="pre">sect</span></code> is a set of the sectors to include, <code class="docutils literal notranslate"><span class="pre">fpath</span></code> is the file path where the
demand data might be located and to where the sectoral demand will be saved (if
desired), and <code class="docutils literal notranslate"><span class="pre">save</span></code> is a boolean that indicates whether the sectoral demand should be
saved. <code class="docutils literal notranslate"><span class="pre">sect</span></code> defaults to including all the sectors (i.e., all sectoral demand is
retained). <code class="docutils literal notranslate"><span class="pre">fpath</span></code> defaults to the current directory. <code class="docutils literal notranslate"><span class="pre">save</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code> (i.e.,
each sectoral demand DataFrame is not saved). <code class="docutils literal notranslate"><span class="pre">partition_demand_by_sector</span></code> returns
<code class="docutils literal notranslate"><span class="pre">sect_dem</span></code>, which is a dictionary of DataFrames, where each DataFrame contains the
demand data for one sector.</p>
<p>The EFS flexibility data for a given electrification scenario is provided for each
sector, year, technology advancement, and flexibility scenario. It is useful to split
the flexibility data by sector for a specific year, technology advancement, and
flexibility scenario. It is useful to split flexibility data by sector because different
sectors may have different operational constraints (e.g., duration between demand
curtailment and recovery, directionality of load shift). EFS flexibility data can be
split by sector as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.get_efs_data</span> <span class="kn">import</span> <span class="n">partition_flexibility_by_sector</span>

<span class="n">sect_dem</span> <span class="o">=</span> <span class="n">partition_flexibility_by_sector</span><span class="p">(</span><span class="n">es</span><span class="p">,</span> <span class="n">ta</span><span class="p">,</span> <span class="n">flex</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">sect</span><span class="p">,</span> <span class="n">fpath</span><span class="p">,</span> <span class="n">save</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">es</span></code> is a string describing a single electrification scenario, <code class="docutils literal notranslate"><span class="pre">ta</span></code> is a string
describing a single technology advancement, flex is a string describing a single
flexibility scenario, <code class="docutils literal notranslate"><span class="pre">year</span></code> is an integer describing the included year, <code class="docutils literal notranslate"><span class="pre">sect</span></code> is a set
of the sectors to include, <code class="docutils literal notranslate"><span class="pre">fpath</span></code> is the file path where the flexibility data might be
located and to where the flexibility demand will be saved (if desired), and <code class="docutils literal notranslate"><span class="pre">save</span></code> is a
boolean that indicates whether the sectoral flexibility data should be saved. <code class="docutils literal notranslate"><span class="pre">sect</span></code>
defaults to including all the sectors (i.e., all sectoral flexibility is retained).
<code class="docutils literal notranslate"><span class="pre">fpath</span></code> defaults to the current directory. <code class="docutils literal notranslate"><span class="pre">save</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code> (i.e., each
sectoral flexibility DataFrame is not saved). <code class="docutils literal notranslate"><span class="pre">partition_flexibility_by_sector</span></code> returns
<code class="docutils literal notranslate"><span class="pre">sect_flex</span></code>, which is a dictionary of DataFrames, where each DataFrame contains the
flexibility data for one sector.</p>
<p><code class="docutils literal notranslate"><span class="pre">partition_demand_by_sector</span></code> and <code class="docutils literal notranslate"><span class="pre">partition_flexibility_by_sector</span></code> check the file path
provided by <code class="docutils literal notranslate"><span class="pre">fpath</span></code> to determine if the data is already downloaded and extracted. If the
data is not present as a <em><strong>.csv</strong></em> file, then <code class="docutils literal notranslate"><span class="pre">partition_demand_by_sector</span></code> and
<code class="docutils literal notranslate"><span class="pre">partition_flexibility_by_sector</span></code> use <code class="docutils literal notranslate"><span class="pre">download_demand_data</span></code> and
<code class="docutils literal notranslate"><span class="pre">download_flexibility_data</span></code>, respectively, to obtain the specified <em><strong>.csv</strong></em> file. If
the automated approach is not able to extract the <em><strong>.csv</strong></em> file,
<code class="docutils literal notranslate"><span class="pre">partition_demand_by_sector</span></code> and <code class="docutils literal notranslate"><span class="pre">partition_flexibility_by_sector</span></code> will exit with an
error, and the user will need to manually use their extraction method of choice (as was
discussed in the prior subsection). If manual extraction is required, the user can
simply run <code class="docutils literal notranslate"><span class="pre">partition_demand_by_sector</span></code> and <code class="docutils literal notranslate"><span class="pre">partition_flexibility_by_sector</span></code> again,
making sure that <code class="docutils literal notranslate"><span class="pre">fpath</span></code> points to the appropriate location where the <em><strong>.csv</strong></em> file is
saved.</p>
</section>
<section id="iii-aggregating-the-sectoral-demand-data">
<h4>III. Aggregating the Sectoral Demand Data<a class="headerlink" href="#iii-aggregating-the-sectoral-demand-data" title="Permalink to this headline">¶</a></h4>
<p>For use in the grid model developed by Breakthrough Energy Sciences, all sectoral demand
must be aggregated within each location for each hour (i.e., only one demand data point
per location per hour). Thus, the sectoral demand must be aggregated together to obtain
a single demand value for each location and each hour. Aggregating sectoral demand can
be accomplished as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.aggregate_demand</span> <span class="kn">import</span> <span class="n">combine_efs_demand</span>

<span class="n">agg_dem</span> <span class="o">=</span> <span class="n">combine_efs_demand</span><span class="p">(</span><span class="n">efs_dem</span><span class="p">,</span> <span class="n">non_efs_dem</span><span class="p">,</span> <span class="n">save</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">efs_dem</span></code> is a dictionary of different sectoral demand DataFrames pertaining to
the EFS (this input is intended to be the output of <code class="docutils literal notranslate"><span class="pre">partition_demand_by_sector</span></code>),
<code class="docutils literal notranslate"><span class="pre">non_efs_dem</span></code> is a list of different sectoral demand DataFrames that are independent of
the EFS (this input is intended to be the output of <code class="docutils literal notranslate"><span class="pre">access_non_efs_demand</span></code>, which is
addressed below), and <code class="docutils literal notranslate"><span class="pre">save</span></code> is a string representing the desired file path and file
name to which the aggregated demand will be saved as a <em><strong>.csv</strong></em> file. Both <code class="docutils literal notranslate"><span class="pre">efs_dem</span></code>
and <code class="docutils literal notranslate"><span class="pre">non_efs_dem</span></code> default to <code class="docutils literal notranslate"><span class="pre">None</span></code>, allowing the user to determine how much sectoral
demand of each type (EFS and non-EFS) they would like to include; note that failing to
specify any sectoral demand will raise an error. <code class="docutils literal notranslate"><span class="pre">save</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>, indicating
that the aggregate demand should not be saved. <code class="docutils literal notranslate"><span class="pre">combine_efs_demand</span></code> returns <code class="docutils literal notranslate"><span class="pre">agg_dem</span></code>,
which is a DataFrame of the aggregate demand data.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">access_non_efs_demand</span></code> function allows sectoral demand that is not associated with
the EFS to be used. <code class="docutils literal notranslate"><span class="pre">access_non_efs_demand</span></code> loads locally-stored sectoral demand data,
checks that it is formatted appropriately, and returns a list of sectoral demand
DataFrames that can be fed into <code class="docutils literal notranslate"><span class="pre">combine_efs_demand</span></code>. Preparing non-EFS sectoral demand
is accomplished as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.aggregate_demand</span> <span class="kn">import</span> <span class="n">access_non_efs_demand</span>

<span class="n">sect_dem</span> <span class="o">=</span> <span class="n">access_non_efs_demand</span><span class="p">(</span><span class="n">dem_paths</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">dem_paths</span></code> is a list of file paths that point to the <em><strong>.csv</strong></em> files of
locally-stored sectoral demand data. <code class="docutils literal notranslate"><span class="pre">access_non_efs_demand</span></code> is intended to be used on
sectoral demand data that is not related to the EFS; all sectoral demand data that is
related to the EFS should be handled using <code class="docutils literal notranslate"><span class="pre">partition_demand_by_sector</span></code>. Note that it
will be incumbent upon the user to account for all sectors when building the aggregate
demand profiles (i.e., users will need to ensure that specific sectors are not excluded
or double-counted).</p>
</section>
<section id="iv-mapping-the-state-demand-to-the-appropriate-load-zones">
<h4>IV. Mapping the State Demand to the Appropriate Load Zones<a class="headerlink" href="#iv-mapping-the-state-demand-to-the-appropriate-load-zones" title="Permalink to this headline">¶</a></h4>
<p>For use in the grid model developed by Breakthrough Energy Sciences, the state-level
demand provided by the EFS must be mapped to the appropriate load zones. Breakthrough
Energy Sciences defines distinct load zones for each state. For smaller states that are
completely contained within a single interconnection, the load zone might very well be
equal to the whole state. However, large states (e.g., California and New York), states
that are in multiple interconnections (e.g., Montana and New Mexico), and states with a
combination of these two characteristics (e.g., Texas) may have multiple load zones.
State-level demand is mapped to the various load zones according to the percentage of a
state’s population that resides in a particular load zone. This mapping can be
accomplished as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.map_states</span> <span class="kn">import</span> <span class="n">decompose_demand_profile_by_state_to_loadzone</span>

<span class="n">df_lz</span> <span class="o">=</span> <span class="n">decompose_demand_profile_by_state_to_loadzone</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">save</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">df</span></code> is a DataFrame of the hourly demand data for each state in the contiguous
U.S. (intended to be the output of <code class="docutils literal notranslate"><span class="pre">combine_efs_demand</span></code> or the components that are
output from <code class="docutils literal notranslate"><span class="pre">partition_flexibility_by_sector</span></code>) and <code class="docutils literal notranslate"><span class="pre">save</span></code> is a string representing the
desired file path and file name to which the demand will be saved as a <em><strong>.csv</strong></em> file.
<code class="docutils literal notranslate"><span class="pre">save</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>, indicating that the demand should not be saved.
<code class="docutils literal notranslate"><span class="pre">decompose_demand_profile_by_state_to_loadzone</span></code> returns <code class="docutils literal notranslate"><span class="pre">df_lz</span></code>, which is a DataFrame of
the demand data mapped to each load zone.</p>
</section>
<section id="v-example-of-downloading-and-preparing-efs-demand-data">
<h4>V. Example of Downloading and Preparing EFS Demand Data<a class="headerlink" href="#v-example-of-downloading-and-preparing-efs-demand-data" title="Permalink to this headline">¶</a></h4>
<p>To demonstrate the work flow of these modules, this subsection presents an example of
obtaining the EFS demand data and subsequently preparing it for use in Breakthrough
Energy Sciences’ grid model. In this example, EFS demand data under the ‘Reference’
electrification scenario and the ‘Slow’ technology advancement are acquired for the year
2030. After mapping the state-level demand to the different load zones, the aggregate
demand is saved as a <em><strong>.csv</strong></em> file to the current working directory. This example is
implemented as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.aggregate_demand</span> <span class="kn">import</span> <span class="n">combine_efs_demand</span>
<span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.get_efs_data</span> <span class="kn">import</span> <span class="n">partition_demand_by_sector</span>
<span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.map_states</span> <span class="kn">import</span> <span class="n">decompose_demand_profile_by_state_to_loadzone</span>

<span class="n">sect_dem</span> <span class="o">=</span> <span class="n">partition_demand_by_sector</span><span class="p">(</span><span class="n">es</span><span class="o">=</span><span class="s2">&quot;Reference&quot;</span><span class="p">,</span> <span class="n">ta</span><span class="o">=</span><span class="s2">&quot;Slow&quot;</span><span class="p">,</span> <span class="n">year</span><span class="o">=</span><span class="mi">2030</span><span class="p">,</span> <span class="n">fpath</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">agg_dem</span> <span class="o">=</span> <span class="n">combine_efs_demand</span><span class="p">(</span><span class="n">efs_dem</span><span class="o">=</span><span class="n">sect_dem</span><span class="p">)</span>
<span class="n">agg_dem_lz</span> <span class="o">=</span> <span class="n">decompose_demand_profile_by_state_to_loadzone</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">agg_dem</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="s2">&quot;EFS_Demand_Reference_Slow_2030.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="vi-example-of-downloading-and-preparing-efs-flexibility-data">
<h4>VI. Example of Downloading and Preparing EFS Flexibility Data<a class="headerlink" href="#vi-example-of-downloading-and-preparing-efs-flexibility-data" title="Permalink to this headline">¶</a></h4>
<p>This subsection presents an example of obtaining the EFS flexibility data and
subsequently preparing it for use in Breakthrough Energy Sciences’ grid model. In this
example, EFS flexibility data under the ‘Reference’ electrification scenario, ‘Slow’
technology advancement, and ‘Base’ flexibility scenario are acquired for the year 2030.
The state-level sectoral flexibility is mapped to the different load zones, however the
different flexibility data are not saved as <em><strong>.csv</strong></em> files as was done in the prior
example. This example is implemented as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.get_efs_data</span> <span class="kn">import</span> <span class="n">partition_flexibility_by_sector</span>
<span class="kn">from</span> <span class="nn">prereise.gather.demanddata.nrel_efs.map_states</span> <span class="kn">import</span> <span class="n">decompose_demand_profile_by_state_to_loadzone</span>

<span class="n">sect_flex</span> <span class="o">=</span> <span class="n">partition_flexibility_by_sector</span><span class="p">(</span><span class="n">es</span><span class="o">=</span><span class="s2">&quot;Reference&quot;</span><span class="p">,</span> <span class="n">ta</span><span class="o">=</span><span class="s2">&quot;Slow&quot;</span><span class="p">,</span> <span class="n">flex</span><span class="o">=</span><span class="s2">&quot;Base&quot;</span><span class="p">,</span> <span class="n">year</span><span class="o">=</span><span class="mi">2030</span><span class="p">,</span> <span class="n">fpath</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">sect_flex_lz</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">decompose_demand_profile_by_state_to_loadzone</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sect_flex</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/img/BE_Sciences_RGB_Horizontal_Color.svg" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Modeling a clean energy future for the United States</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=Breakthrough-Energy&repo=docs&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="user/installation_guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="communication/code_of_conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="dev/contribution_guide.html">Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="user/git_guide.html">Working with Git</a></li>
<li class="toctree-l1"><a class="reference internal" href="powersimdata/index.html">PowerSimData</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">PreREISE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#setup-install">1. Setup/Install</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#a-using-pipenv">A. Using pipenv</a></li>
<li class="toctree-l3"><a class="reference internal" href="#b-using-the-requirements-txt-file">B. Using the <em><strong>requirements.txt</strong></em> file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#c-path">C. Path</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#gather-data-for-simulation">2. Gather Data for Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#profile-naming-convention">Profile Naming Convention</a></li>
<li class="toctree-l3"><a class="reference internal" href="#a-wind-data">A. Wind data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#b-solar-data">B. Solar data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#c-hydro-data">C. Hydro Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#d-demand-data">D. Demand Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#e-nrel-electrification-futures-study-demand-and-flexibility-data">E. NREL Electrification Futures Study Demand and Flexibility Data</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="postreise/index.html">PostREISE</a></li>
<li class="toctree-l1"><a class="reference internal" href="reisejl_package.html">REISE.jl</a></li>
</ul>

<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="powersimdata/index.html" title="previous chapter">PowerSimData</a></li>
      <li>Next: <a href="postreise/index.html" title="next chapter">PostREISE</a></li>
  </ul></li>
</ul><h3>Useful Links</h3>
<ul>
  <li><a href="https://www.breakthroughenergy.org/">Breakthrough Energy</a></li>
  <li><a href="https://science.breakthroughenergy.org/">Breakthrough Energy Sciences</a></li>
  <li><a href="https://arxiv.org/abs/2002.06155">publication</a></li>
  <li><a href="https://zenodo.org/record/3530898">data @ zenodo</a></li>
</ul>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script><ul>
<h3>Code</h3>
<a href="py-modindex.html">Module Index</a>
</ul>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Breakthrough Energy Foundation.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/prereise_package.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>